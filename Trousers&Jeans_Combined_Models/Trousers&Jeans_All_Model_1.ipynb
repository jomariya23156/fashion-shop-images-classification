{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "steady-point",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-burden",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "british-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('dataset/Trousers & Jeans - All - Train.npz')\n",
    "validation_data = np.load('dataset/Trousers & Jeans - All - Validation.npz')\n",
    "test_data = np.load('dataset/Trousers & Jeans - All - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "described-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'labels', 'genders']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = train_data['images'], train_data['labels']\n",
    "images_val, labels_val = validation_data['images'], validation_data['labels']\n",
    "images_test, labels_test = test_data['images'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subject-devil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "duplicate-cedar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4004, 120, 90, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "korean-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4004,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conditional-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 120, 90, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fifth-dietary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collected-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 120, 90, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "productive-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fleet-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize \n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-conspiracy",
   "metadata": {},
   "source": [
    "## Create the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-summary",
   "metadata": {},
   "source": [
    "### Define hyparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "scheduled-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_KERNEL_SIZE = hp.HParam('kernel size', hp.Discrete([3,5,7]))\n",
    "HP_KERNEL_NUM = hp.HParam('kernel num', hp.Discrete([32,64,96,128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "registered-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'Logs/Model 1 (Trousers&Jeans_All)/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams = [HP_KERNEL_SIZE, HP_KERNEL_NUM],\n",
    "        metrics = [hp.Metric(METRIC, display_name='accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-individual",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.Seqeuntial([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_KERNEL_NUM], hparams[HP_KERNEL_SIZE], activation = 'relu', input_shape(120,9,3)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer = 'adam', loss = loss_fn, metrics = ['accuracy'])\n",
    "    \n",
    "    log_dir = \"Logs\\\\Model 1 (Trousers&Jeans_All)\\\\fit\\\\\" + f\"run-{session_num}\"\n",
    "    \n",
    "    # functions for creating confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "        plt.close(figure)\n",
    "\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Define a file writer variable for logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Trousers Male','Jeans Male','Trousers Female','Jeans Female'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            \n",
    "    # callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = log_confusion_matrix)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq = 1, profile_batch = 0)\n",
    "    \n",
    "    model.fit(images_train,\n",
    "              labels_train,\n",
    "              epochs = EPOCHS,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "              validation_data = (images_val, labels_val),\n",
    "              verbose = 1)\n",
    "    \n",
    "    _, accuracy = model.evaluate(images_val, labels_val)\n",
    "    \n",
    "    model.save(r'saved_models\\Model 1 (Trousers&Jeans_All)\\Run-{}'.format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 1\n",
    "for kernel_size in HP_KERNEL_SIZE.domain.values:\n",
    "    for kernel_num in HP_KERNEL_NUM.domain.values:\n",
    "        hparams = {\n",
    "            HP_KERNEL_SIZE : kernel_size,\n",
    "            HP_KERNEL_NUM : kernel_num\n",
    "        }\n",
    "        run_name = f'run-{session_num}'\n",
    "        print('--- Starting Trial:',run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run(\"Logs/Model 1 (Trousers&Jeans_All)/hparam_tuning/\" + run_name, hparams, session_num)\n",
    "        \n",
    "        session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TF2)",
   "language": "python",
   "name": "python3-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
