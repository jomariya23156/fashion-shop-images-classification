{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "popular-member",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "together-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-neighborhood",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "preceding-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('dataset/Shoes - Female - Train.npz')\n",
    "validation_data = np.load('dataset/Shoes - Female - Validation.npz')\n",
    "test_data = np.load('dataset/Shoes - Female - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reverse-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'labels']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "downtown-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = train_data['images'], train_data['labels']\n",
    "images_val, labels_val = validation_data['images'], validation_data['labels']\n",
    "images_test, labels_test = test_data['images'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aggressive-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2886, 120, 90, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "equipped-response",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2886,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "significant-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# Flip the image by flip the axis 2\n",
    "# we have 4 axis now in images (no. of pic, y, x, channel)\n",
    "# so, if we want to flip horizontally, we flip axis 2\n",
    "\n",
    "flipped_images_train = np.flip(images_train, axis = 2)\n",
    "flipped_images_val = np.flip(images_val, axis = 2)\n",
    "flipped_images_test = np.flip(images_test, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "behavioral-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to concatenate labels with itself, cuz we increase pic in images, so labels have to be increased too.\n",
    "images_train = np.concatenate((images_train, flipped_images_train))\n",
    "labels_train = np.concatenate((labels_train, labels_train))\n",
    "\n",
    "images_val = np.concatenate((images_val, flipped_images_val))\n",
    "labels_val = np.concatenate((labels_val, labels_val))\n",
    "\n",
    "images_test = np.concatenate((images_test, flipped_images_test))\n",
    "labels_test = np.concatenate((labels_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "civil-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 120, 90, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "healthy-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "responsible-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 120, 90, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alternative-promotion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "criminal-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "derived-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-warehouse",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-controversy",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "gross-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "manual-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_KERNEL_SIZE = hp.HParam('kernel size', hp.Discrete([3,5,7]))\n",
    "HP_KERNEL_NUM = hp.HParam('kernel num', hp.Discrete([64,128]))\n",
    "HP_LAMBDA_REG = hp.HParam('lambda reg', hp.Discrete([1e-5,5e-5,1e-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "surprising-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'logs/Model 1 (Shoes_Female_L2)/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams = [HP_KERNEL_SIZE, HP_KERNEL_NUM, HP_LAMBDA_REG],\n",
    "        metrics = [hp.Metric(METRIC, display_name = 'accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-region",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "assumed-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_KERNEL_NUM], hparams[HP_KERNEL_SIZE], activation = 'relu', input_shape = (120,90,3), kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_KERNEL_NUM], hparams[HP_KERNEL_SIZE], activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.Dense(6, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(name = 'sparse_categorical_crossentropy')\n",
    "    model.compile(optimizer = 'adam', loss = loss_fn, metrics = ['accuracy','sparse_categorical_crossentropy'])\n",
    "    \n",
    "    log_dir = \"Logs\\\\Model 1 (Shoes_Female_L2)\\\\fit\\\\\" + f\"run-{session_num}\"\n",
    "    \n",
    "    # functions for creating confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "        plt.close(figure)\n",
    "\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Define a file writer variable for logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Boots','Ballerina', 'Trainers/Sneakers',\n",
    "                                                        'High heels', 'Sandals/Flip flops/Slippers',\n",
    "                                                        'Others'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            \n",
    "    # callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_sparse_categorical_crossentropy', patience = 2, restore_best_weights = True)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1, profile_batch = 0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = log_confusion_matrix)\n",
    "    \n",
    "    model.fit(images_train,\n",
    "              labels_train,\n",
    "              epochs = EPOCHS,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "              validation_data = (images_val, labels_val),\n",
    "              verbose = 1)\n",
    "    \n",
    "    _, accuracy, _ = model.evaluate(images_val, labels_val)\n",
    "    \n",
    "    model.save(r'saved_models\\Model 1 (Shoes_Female_L2)\\Run-{}'.format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "sublime-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sensitive-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Trial: run-1\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 58s 634ms/step - loss: 1.1441 - accuracy: 0.6157 - sparse_categorical_crossentropy: 1.1372 - val_loss: 0.6877 - val_accuracy: 0.7861 - val_sparse_categorical_crossentropy: 0.6802\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 58s 634ms/step - loss: 0.5933 - accuracy: 0.7949 - sparse_categorical_crossentropy: 0.5852 - val_loss: 0.5891 - val_accuracy: 0.7972 - val_sparse_categorical_crossentropy: 0.5803\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 58s 635ms/step - loss: 0.4400 - accuracy: 0.8540 - sparse_categorical_crossentropy: 0.4302 - val_loss: 0.4705 - val_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.4600\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 58s 636ms/step - loss: 0.3213 - accuracy: 0.8928 - sparse_categorical_crossentropy: 0.3101 - val_loss: 0.4313 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.4195\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 62s 680ms/step - loss: 0.2653 - accuracy: 0.9156 - sparse_categorical_crossentropy: 0.2529 - val_loss: 0.4408 - val_accuracy: 0.8792 - val_sparse_categorical_crossentropy: 0.4279\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 73s 806ms/step - loss: 0.1968 - accuracy: 0.9428 - sparse_categorical_crossentropy: 0.1833 - val_loss: 0.3802 - val_accuracy: 0.8986 - val_sparse_categorical_crossentropy: 0.3663\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 90s 989ms/step - loss: 0.1578 - accuracy: 0.9506 - sparse_categorical_crossentropy: 0.1434 - val_loss: 0.4276 - val_accuracy: 0.8819 - val_sparse_categorical_crossentropy: 0.4125\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 60s 665ms/step - loss: 0.1374 - accuracy: 0.9602 - sparse_categorical_crossentropy: 0.1219 - val_loss: 0.4505 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.4347\n",
      "23/23 [==============================] - 2s 101ms/step - loss: 0.3802 - accuracy: 0.8986 - sparse_categorical_crossentropy: 0.3663\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-1\\assets\n",
      "--- Starting Trial: run-2\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 61s 675ms/step - loss: 1.1564 - accuracy: 0.6100 - sparse_categorical_crossentropy: 1.1288 - val_loss: 1.4451 - val_accuracy: 0.5514 - val_sparse_categorical_crossentropy: 1.4153\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 60s 658ms/step - loss: 0.6554 - accuracy: 0.7956 - sparse_categorical_crossentropy: 0.6231 - val_loss: 0.5662 - val_accuracy: 0.8486 - val_sparse_categorical_crossentropy: 0.5322\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 61s 665ms/step - loss: 0.4768 - accuracy: 0.8482 - sparse_categorical_crossentropy: 0.4409 - val_loss: 0.5424 - val_accuracy: 0.8528 - val_sparse_categorical_crossentropy: 0.5043\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 60s 662ms/step - loss: 0.3547 - accuracy: 0.8952 - sparse_categorical_crossentropy: 0.3143 - val_loss: 0.4866 - val_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.4444\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 62s 685ms/step - loss: 0.3080 - accuracy: 0.9073 - sparse_categorical_crossentropy: 0.2636 - val_loss: 0.4837 - val_accuracy: 0.8806 - val_sparse_categorical_crossentropy: 0.4369\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 61s 667ms/step - loss: 0.2280 - accuracy: 0.9381 - sparse_categorical_crossentropy: 0.1809 - val_loss: 0.4970 - val_accuracy: 0.8750 - val_sparse_categorical_crossentropy: 0.4494\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 60s 656ms/step - loss: 0.1811 - accuracy: 0.9570 - sparse_categorical_crossentropy: 0.1331 - val_loss: 0.4755 - val_accuracy: 0.8972 - val_sparse_categorical_crossentropy: 0.4271\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.1781 - accuracy: 0.9576 - sparse_categorical_crossentropy: 0.1281 - val_loss: 0.4910 - val_accuracy: 0.8903 - val_sparse_categorical_crossentropy: 0.4394\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 61s 665ms/step - loss: 0.1605 - accuracy: 0.9650 - sparse_categorical_crossentropy: 0.1078 - val_loss: 0.5217 - val_accuracy: 0.8958 - val_sparse_categorical_crossentropy: 0.4667\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.4755 - accuracy: 0.8972 - sparse_categorical_crossentropy: 0.4271\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-2\\assets\n",
      "--- Starting Trial: run-3\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 72s 789ms/step - loss: 1.3296 - accuracy: 0.5885 - sparse_categorical_crossentropy: 1.2793 - val_loss: 0.7688 - val_accuracy: 0.7681 - val_sparse_categorical_crossentropy: 0.7181\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 65s 717ms/step - loss: 0.6519 - accuracy: 0.7973 - sparse_categorical_crossentropy: 0.6000 - val_loss: 0.6163 - val_accuracy: 0.8181 - val_sparse_categorical_crossentropy: 0.5637\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 64s 706ms/step - loss: 0.4954 - accuracy: 0.8520 - sparse_categorical_crossentropy: 0.4417 - val_loss: 0.4866 - val_accuracy: 0.8486 - val_sparse_categorical_crossentropy: 0.4319\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 65s 711ms/step - loss: 0.4195 - accuracy: 0.8789 - sparse_categorical_crossentropy: 0.3625 - val_loss: 0.5074 - val_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.4482\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 65s 712ms/step - loss: 0.3475 - accuracy: 0.9038 - sparse_categorical_crossentropy: 0.2863 - val_loss: 0.4745 - val_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.4117\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 62s 682ms/step - loss: 0.3066 - accuracy: 0.9168 - sparse_categorical_crossentropy: 0.2407 - val_loss: 0.4617 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.3938\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 61s 667ms/step - loss: 0.2667 - accuracy: 0.9310 - sparse_categorical_crossentropy: 0.1977 - val_loss: 0.4682 - val_accuracy: 0.8847 - val_sparse_categorical_crossentropy: 0.3978\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 60s 659ms/step - loss: 0.2183 - accuracy: 0.9541 - sparse_categorical_crossentropy: 0.1472 - val_loss: 0.5494 - val_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.4779\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.4617 - accuracy: 0.8861 - sparse_categorical_crossentropy: 0.3938\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-3\\assets\n",
      "--- Starting Trial: run-4\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 139s 2s/step - loss: 1.2990 - accuracy: 0.5889 - sparse_categorical_crossentropy: 1.2907 - val_loss: 0.7096 - val_accuracy: 0.7472 - val_sparse_categorical_crossentropy: 0.7010\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 140s 2s/step - loss: 0.5914 - accuracy: 0.8011 - sparse_categorical_crossentropy: 0.5826 - val_loss: 0.5314 - val_accuracy: 0.8292 - val_sparse_categorical_crossentropy: 0.5225\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 142s 2s/step - loss: 0.4246 - accuracy: 0.8633 - sparse_categorical_crossentropy: 0.4152 - val_loss: 0.4611 - val_accuracy: 0.8625 - val_sparse_categorical_crossentropy: 0.4513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "91/91 [==============================] - 135s 1s/step - loss: 0.3572 - accuracy: 0.8786 - sparse_categorical_crossentropy: 0.3470 - val_loss: 0.5563 - val_accuracy: 0.8542 - val_sparse_categorical_crossentropy: 0.5454\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 143s 2s/step - loss: 0.2705 - accuracy: 0.9103 - sparse_categorical_crossentropy: 0.2592 - val_loss: 0.4713 - val_accuracy: 0.8778 - val_sparse_categorical_crossentropy: 0.4597\n",
      "23/23 [==============================] - 5s 197ms/step - loss: 0.4611 - accuracy: 0.8625 - sparse_categorical_crossentropy: 0.4513\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-4\\assets\n",
      "--- Starting Trial: run-5\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 140s 2s/step - loss: 1.4443 - accuracy: 0.5324 - sparse_categorical_crossentropy: 1.4124 - val_loss: 0.7741 - val_accuracy: 0.7431 - val_sparse_categorical_crossentropy: 0.7442\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 138s 2s/step - loss: 0.6939 - accuracy: 0.7696 - sparse_categorical_crossentropy: 0.6647 - val_loss: 0.5653 - val_accuracy: 0.8319 - val_sparse_categorical_crossentropy: 0.5367\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 142s 2s/step - loss: 0.5289 - accuracy: 0.8299 - sparse_categorical_crossentropy: 0.5005 - val_loss: 0.6006 - val_accuracy: 0.8153 - val_sparse_categorical_crossentropy: 0.5718\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 137s 2s/step - loss: 0.4225 - accuracy: 0.8678 - sparse_categorical_crossentropy: 0.3925 - val_loss: 0.4916 - val_accuracy: 0.8389 - val_sparse_categorical_crossentropy: 0.4610\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 139s 2s/step - loss: 0.3381 - accuracy: 0.8966 - sparse_categorical_crossentropy: 0.3070 - val_loss: 0.5389 - val_accuracy: 0.8361 - val_sparse_categorical_crossentropy: 0.5070\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 140s 2s/step - loss: 0.3068 - accuracy: 0.9070 - sparse_categorical_crossentropy: 0.2739 - val_loss: 0.4620 - val_accuracy: 0.8722 - val_sparse_categorical_crossentropy: 0.4283\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 141s 2s/step - loss: 0.2494 - accuracy: 0.9255 - sparse_categorical_crossentropy: 0.2153 - val_loss: 0.4695 - val_accuracy: 0.8819 - val_sparse_categorical_crossentropy: 0.4350\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 136s 1s/step - loss: 0.1991 - accuracy: 0.9447 - sparse_categorical_crossentropy: 0.1641 - val_loss: 0.5167 - val_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.4814\n",
      "23/23 [==============================] - 4s 190ms/step - loss: 0.4620 - accuracy: 0.8722 - sparse_categorical_crossentropy: 0.4283\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-5\\assets\n",
      "--- Starting Trial: run-6\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 150s 2s/step - loss: 1.3532 - accuracy: 0.6000 - sparse_categorical_crossentropy: 1.2933 - val_loss: 0.6288 - val_accuracy: 0.8097 - val_sparse_categorical_crossentropy: 0.5715\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 143s 2s/step - loss: 0.6414 - accuracy: 0.7982 - sparse_categorical_crossentropy: 0.5853 - val_loss: 0.6423 - val_accuracy: 0.8056 - val_sparse_categorical_crossentropy: 0.5862\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 144s 2s/step - loss: 0.5021 - accuracy: 0.8465 - sparse_categorical_crossentropy: 0.4442 - val_loss: 0.4987 - val_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.4385\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 141s 2s/step - loss: 0.3918 - accuracy: 0.8846 - sparse_categorical_crossentropy: 0.3295 - val_loss: 0.4712 - val_accuracy: 0.8889 - val_sparse_categorical_crossentropy: 0.4063\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 141s 2s/step - loss: 0.3190 - accuracy: 0.9146 - sparse_categorical_crossentropy: 0.2525 - val_loss: 0.4555 - val_accuracy: 0.8819 - val_sparse_categorical_crossentropy: 0.3871\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 141s 2s/step - loss: 0.2677 - accuracy: 0.9343 - sparse_categorical_crossentropy: 0.1973 - val_loss: 0.4544 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.3824\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 141s 2s/step - loss: 0.2250 - accuracy: 0.9505 - sparse_categorical_crossentropy: 0.1524 - val_loss: 0.5142 - val_accuracy: 0.8806 - val_sparse_categorical_crossentropy: 0.4404\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 145s 2s/step - loss: 0.2053 - accuracy: 0.9576 - sparse_categorical_crossentropy: 0.1310 - val_loss: 0.4915 - val_accuracy: 0.9000 - val_sparse_categorical_crossentropy: 0.4161\n",
      "23/23 [==============================] - 5s 204ms/step - loss: 0.4544 - accuracy: 0.8861 - sparse_categorical_crossentropy: 0.3824\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-6\\assets\n",
      "--- Starting Trial: run-7\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 95s 1s/step - loss: 1.3294 - accuracy: 0.5544 - sparse_categorical_crossentropy: 1.3235 - val_loss: 1.0043 - val_accuracy: 0.6097 - val_sparse_categorical_crossentropy: 0.9984\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 97s 1s/step - loss: 0.7244 - accuracy: 0.7543 - sparse_categorical_crossentropy: 0.7183 - val_loss: 0.7761 - val_accuracy: 0.7444 - val_sparse_categorical_crossentropy: 0.7697\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 96s 1s/step - loss: 0.5191 - accuracy: 0.8333 - sparse_categorical_crossentropy: 0.5123 - val_loss: 0.5613 - val_accuracy: 0.8194 - val_sparse_categorical_crossentropy: 0.5542\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 99s 1s/step - loss: 0.4009 - accuracy: 0.8659 - sparse_categorical_crossentropy: 0.3934 - val_loss: 0.4345 - val_accuracy: 0.8583 - val_sparse_categorical_crossentropy: 0.4267\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 95s 1s/step - loss: 0.2998 - accuracy: 0.9002 - sparse_categorical_crossentropy: 0.2917 - val_loss: 0.4357 - val_accuracy: 0.8778 - val_sparse_categorical_crossentropy: 0.4272\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 94s 1s/step - loss: 0.2812 - accuracy: 0.9028 - sparse_categorical_crossentropy: 0.2723 - val_loss: 0.4015 - val_accuracy: 0.8806 - val_sparse_categorical_crossentropy: 0.3921\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 87s 960ms/step - loss: 0.1975 - accuracy: 0.9330 - sparse_categorical_crossentropy: 0.1879 - val_loss: 0.3621 - val_accuracy: 0.8986 - val_sparse_categorical_crossentropy: 0.3522\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.1525 - accuracy: 0.9520 - sparse_categorical_crossentropy: 0.1422 - val_loss: 0.4610 - val_accuracy: 0.8944 - val_sparse_categorical_crossentropy: 0.4504\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 89s 983ms/step - loss: 0.1223 - accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1116 - val_loss: 0.4065 - val_accuracy: 0.8986 - val_sparse_categorical_crossentropy: 0.3958\n",
      "23/23 [==============================] - 3s 147ms/step - loss: 0.3621 - accuracy: 0.8986 - sparse_categorical_crossentropy: 0.3522\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-7\\assets\n",
      "--- Starting Trial: run-8\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 100s 1s/step - loss: 1.1759 - accuracy: 0.5832 - sparse_categorical_crossentropy: 1.1473 - val_loss: 0.9643 - val_accuracy: 0.6417 - val_sparse_categorical_crossentropy: 0.9357\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 113s 1s/step - loss: 0.7198 - accuracy: 0.7630 - sparse_categorical_crossentropy: 0.6903 - val_loss: 0.7535 - val_accuracy: 0.7639 - val_sparse_categorical_crossentropy: 0.7227\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.4943 - accuracy: 0.8477 - sparse_categorical_crossentropy: 0.4622 - val_loss: 0.5429 - val_accuracy: 0.8389 - val_sparse_categorical_crossentropy: 0.5095\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 89s 977ms/step - loss: 0.3636 - accuracy: 0.8889 - sparse_categorical_crossentropy: 0.3287 - val_loss: 0.4887 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.4521\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 90s 991ms/step - loss: 0.3127 - accuracy: 0.9058 - sparse_categorical_crossentropy: 0.2749 - val_loss: 0.5031 - val_accuracy: 0.8528 - val_sparse_categorical_crossentropy: 0.4638\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 89s 983ms/step - loss: 0.2327 - accuracy: 0.9319 - sparse_categorical_crossentropy: 0.1923 - val_loss: 0.4701 - val_accuracy: 0.8639 - val_sparse_categorical_crossentropy: 0.4289\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 90s 989ms/step - loss: 0.2025 - accuracy: 0.9446 - sparse_categorical_crossentropy: 0.1600 - val_loss: 0.4361 - val_accuracy: 0.8819 - val_sparse_categorical_crossentropy: 0.3927\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.1792 - accuracy: 0.9565 - sparse_categorical_crossentropy: 0.1350 - val_loss: 0.4335 - val_accuracy: 0.8875 - val_sparse_categorical_crossentropy: 0.3887\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 97s 1s/step - loss: 0.1467 - accuracy: 0.9674 - sparse_categorical_crossentropy: 0.1006 - val_loss: 0.4561 - val_accuracy: 0.8875 - val_sparse_categorical_crossentropy: 0.4094\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.1305 - accuracy: 0.9752 - sparse_categorical_crossentropy: 0.0827 - val_loss: 0.4279 - val_accuracy: 0.8958 - val_sparse_categorical_crossentropy: 0.3788\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.1157 - accuracy: 0.9806 - sparse_categorical_crossentropy: 0.0665 - val_loss: 0.4775 - val_accuracy: 0.8986 - val_sparse_categorical_crossentropy: 0.4282\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 91s 997ms/step - loss: 0.1049 - accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0546 - val_loss: 0.5037 - val_accuracy: 0.8903 - val_sparse_categorical_crossentropy: 0.4525\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.4279 - accuracy: 0.8958 - sparse_categorical_crossentropy: 0.3788\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-8\\assets\n",
      "--- Starting Trial: run-9\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 90s 984ms/step - loss: 1.4798 - accuracy: 0.5033 - sparse_categorical_crossentropy: 1.4322 - val_loss: 0.8191 - val_accuracy: 0.7319 - val_sparse_categorical_crossentropy: 0.7734\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.7528 - accuracy: 0.7503 - sparse_categorical_crossentropy: 0.7085 - val_loss: 0.6921 - val_accuracy: 0.7833 - val_sparse_categorical_crossentropy: 0.6485\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 89s 975ms/step - loss: 0.5679 - accuracy: 0.8273 - sparse_categorical_crossentropy: 0.5235 - val_loss: 0.5835 - val_accuracy: 0.8111 - val_sparse_categorical_crossentropy: 0.5383\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 88s 969ms/step - loss: 0.4507 - accuracy: 0.8605 - sparse_categorical_crossentropy: 0.4041 - val_loss: 0.4916 - val_accuracy: 0.8597 - val_sparse_categorical_crossentropy: 0.4439\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 87s 961ms/step - loss: 0.3588 - accuracy: 0.8915 - sparse_categorical_crossentropy: 0.3095 - val_loss: 0.4937 - val_accuracy: 0.8486 - val_sparse_categorical_crossentropy: 0.4429\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 88s 966ms/step - loss: 0.3208 - accuracy: 0.9038 - sparse_categorical_crossentropy: 0.2684 - val_loss: 0.4612 - val_accuracy: 0.8611 - val_sparse_categorical_crossentropy: 0.4070\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 89s 977ms/step - loss: 0.2806 - accuracy: 0.9191 - sparse_categorical_crossentropy: 0.2245 - val_loss: 0.5037 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.4462\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.2480 - accuracy: 0.9335 - sparse_categorical_crossentropy: 0.1897 - val_loss: 0.5173 - val_accuracy: 0.8708 - val_sparse_categorical_crossentropy: 0.4581\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.4612 - accuracy: 0.8611 - sparse_categorical_crossentropy: 0.4070\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-9\\assets\n",
      "--- Starting Trial: run-10\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 222s 2s/step - loss: 1.5495 - accuracy: 0.5256 - sparse_categorical_crossentropy: 1.5419 - val_loss: 0.8418 - val_accuracy: 0.7333 - val_sparse_categorical_crossentropy: 0.8341\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 217s 2s/step - loss: 0.7876 - accuracy: 0.7379 - sparse_categorical_crossentropy: 0.7799 - val_loss: 0.6291 - val_accuracy: 0.8167 - val_sparse_categorical_crossentropy: 0.6214\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 215s 2s/step - loss: 0.7661 - accuracy: 0.7427 - sparse_categorical_crossentropy: 0.7583 - val_loss: 0.6194 - val_accuracy: 0.7931 - val_sparse_categorical_crossentropy: 0.6115\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 216s 2s/step - loss: 0.4818 - accuracy: 0.8429 - sparse_categorical_crossentropy: 0.4737 - val_loss: 0.5188 - val_accuracy: 0.8236 - val_sparse_categorical_crossentropy: 0.5106\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 216s 2s/step - loss: 0.3740 - accuracy: 0.8735 - sparse_categorical_crossentropy: 0.3657 - val_loss: 0.5070 - val_accuracy: 0.8444 - val_sparse_categorical_crossentropy: 0.4985\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 218s 2s/step - loss: 0.3114 - accuracy: 0.8950 - sparse_categorical_crossentropy: 0.3027 - val_loss: 0.4591 - val_accuracy: 0.8514 - val_sparse_categorical_crossentropy: 0.4502\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.2574 - accuracy: 0.9116 - sparse_categorical_crossentropy: 0.2484 - val_loss: 0.4585 - val_accuracy: 0.8722 - val_sparse_categorical_crossentropy: 0.4492\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 214s 2s/step - loss: 0.2456 - accuracy: 0.9135 - sparse_categorical_crossentropy: 0.2361 - val_loss: 0.5427 - val_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.5329\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 215s 2s/step - loss: 0.1913 - accuracy: 0.9392 - sparse_categorical_crossentropy: 0.1812 - val_loss: 0.4763 - val_accuracy: 0.8708 - val_sparse_categorical_crossentropy: 0.4661\n",
      "23/23 [==============================] - 7s 313ms/step - loss: 0.4585 - accuracy: 0.8722 - sparse_categorical_crossentropy: 0.4492\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-10\\assets\n",
      "--- Starting Trial: run-11\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 217s 2s/step - loss: 1.4458 - accuracy: 0.5211 - sparse_categorical_crossentropy: 1.4137 - val_loss: 0.7576 - val_accuracy: 0.7597 - val_sparse_categorical_crossentropy: 0.7278\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 216s 2s/step - loss: 0.7007 - accuracy: 0.7704 - sparse_categorical_crossentropy: 0.6727 - val_loss: 0.6581 - val_accuracy: 0.7903 - val_sparse_categorical_crossentropy: 0.6312\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 217s 2s/step - loss: 0.5806 - accuracy: 0.8068 - sparse_categorical_crossentropy: 0.5534 - val_loss: 0.5591 - val_accuracy: 0.8278 - val_sparse_categorical_crossentropy: 0.5319\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 218s 2s/step - loss: 0.4547 - accuracy: 0.8586 - sparse_categorical_crossentropy: 0.4273 - val_loss: 0.6591 - val_accuracy: 0.8125 - val_sparse_categorical_crossentropy: 0.6313\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 217s 2s/step - loss: 0.5222 - accuracy: 0.8347 - sparse_categorical_crossentropy: 0.4933 - val_loss: 0.5677 - val_accuracy: 0.8403 - val_sparse_categorical_crossentropy: 0.5374\n",
      "23/23 [==============================] - 7s 313ms/step - loss: 0.5591 - accuracy: 0.8278 - sparse_categorical_crossentropy: 0.5319\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Trial: run-12\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 218s 2s/step - loss: 1.5281 - accuracy: 0.5100 - sparse_categorical_crossentropy: 1.4711 - val_loss: 0.8802 - val_accuracy: 0.7361 - val_sparse_categorical_crossentropy: 0.8278\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 218s 2s/step - loss: 0.8080 - accuracy: 0.7370 - sparse_categorical_crossentropy: 0.7587 - val_loss: 0.6922 - val_accuracy: 0.7819 - val_sparse_categorical_crossentropy: 0.6441\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 224s 2s/step - loss: 0.6435 - accuracy: 0.7975 - sparse_categorical_crossentropy: 0.5952 - val_loss: 0.5559 - val_accuracy: 0.8403 - val_sparse_categorical_crossentropy: 0.5079\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.4930 - accuracy: 0.8484 - sparse_categorical_crossentropy: 0.4451 - val_loss: 0.6106 - val_accuracy: 0.8028 - val_sparse_categorical_crossentropy: 0.5619\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 247s 3s/step - loss: 0.4260 - accuracy: 0.8690 - sparse_categorical_crossentropy: 0.3767 - val_loss: 0.5888 - val_accuracy: 0.8194 - val_sparse_categorical_crossentropy: 0.5391\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.5559 - accuracy: 0.8403 - sparse_categorical_crossentropy: 0.5079\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-12\\assets\n",
      "--- Starting Trial: run-13\n",
      "{'kernel size': 7, 'kernel num': 64, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 130s 1s/step - loss: 1.4709 - accuracy: 0.4324 - sparse_categorical_crossentropy: 1.4648 - val_loss: 0.9649 - val_accuracy: 0.6722 - val_sparse_categorical_crossentropy: 0.9588\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 140s 2s/step - loss: 0.8802 - accuracy: 0.6833 - sparse_categorical_crossentropy: 0.8743 - val_loss: 0.8013 - val_accuracy: 0.7306 - val_sparse_categorical_crossentropy: 0.7954\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 131s 1s/step - loss: 0.7117 - accuracy: 0.7481 - sparse_categorical_crossentropy: 0.7058 - val_loss: 0.6090 - val_accuracy: 0.7903 - val_sparse_categorical_crossentropy: 0.6030\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 133s 1s/step - loss: 0.5656 - accuracy: 0.8049 - sparse_categorical_crossentropy: 0.5596 - val_loss: 0.5257 - val_accuracy: 0.8236 - val_sparse_categorical_crossentropy: 0.5197\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 139s 2s/step - loss: 0.4597 - accuracy: 0.8396 - sparse_categorical_crossentropy: 0.4537 - val_loss: 0.4835 - val_accuracy: 0.8444 - val_sparse_categorical_crossentropy: 0.4773\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 145s 2s/step - loss: 0.3641 - accuracy: 0.8805 - sparse_categorical_crossentropy: 0.3577 - val_loss: 0.5644 - val_accuracy: 0.8208 - val_sparse_categorical_crossentropy: 0.5578\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 133s 1s/step - loss: 0.3145 - accuracy: 0.8935 - sparse_categorical_crossentropy: 0.3078 - val_loss: 0.4460 - val_accuracy: 0.8597 - val_sparse_categorical_crossentropy: 0.4393\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 131s 1s/step - loss: 0.2774 - accuracy: 0.9059 - sparse_categorical_crossentropy: 0.2706 - val_loss: 0.3885 - val_accuracy: 0.8931 - val_sparse_categorical_crossentropy: 0.3816\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 130s 1s/step - loss: 0.1986 - accuracy: 0.9314 - sparse_categorical_crossentropy: 0.1917 - val_loss: 0.4185 - val_accuracy: 0.8792 - val_sparse_categorical_crossentropy: 0.4114\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.2226 - accuracy: 0.9229 - sparse_categorical_crossentropy: 0.2153 - val_loss: 0.4548 - val_accuracy: 0.8764 - val_sparse_categorical_crossentropy: 0.4474\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.3885 - accuracy: 0.8931 - sparse_categorical_crossentropy: 0.3816\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-13\\assets\n",
      "--- Starting Trial: run-14\n",
      "{'kernel size': 7, 'kernel num': 64, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 129s 1s/step - loss: 1.3997 - accuracy: 0.5094 - sparse_categorical_crossentropy: 1.3731 - val_loss: 0.8626 - val_accuracy: 0.7083 - val_sparse_categorical_crossentropy: 0.8373\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.8711 - accuracy: 0.7110 - sparse_categorical_crossentropy: 0.8470 - val_loss: 0.7608 - val_accuracy: 0.7444 - val_sparse_categorical_crossentropy: 0.7376\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.6298 - accuracy: 0.7921 - sparse_categorical_crossentropy: 0.6069 - val_loss: 0.5613 - val_accuracy: 0.8319 - val_sparse_categorical_crossentropy: 0.5380\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.4697 - accuracy: 0.8507 - sparse_categorical_crossentropy: 0.4462 - val_loss: 0.5542 - val_accuracy: 0.8181 - val_sparse_categorical_crossentropy: 0.5305\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.3923 - accuracy: 0.8701 - sparse_categorical_crossentropy: 0.3685 - val_loss: 0.4889 - val_accuracy: 0.8667 - val_sparse_categorical_crossentropy: 0.4649\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 129s 1s/step - loss: 0.3128 - accuracy: 0.8992 - sparse_categorical_crossentropy: 0.2885 - val_loss: 0.4314 - val_accuracy: 0.8792 - val_sparse_categorical_crossentropy: 0.4069\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.2554 - accuracy: 0.9177 - sparse_categorical_crossentropy: 0.2308 - val_loss: 0.5105 - val_accuracy: 0.8667 - val_sparse_categorical_crossentropy: 0.4857\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.2126 - accuracy: 0.9354 - sparse_categorical_crossentropy: 0.1877 - val_loss: 0.5581 - val_accuracy: 0.8639 - val_sparse_categorical_crossentropy: 0.5329\n",
      "23/23 [==============================] - 4s 175ms/step - loss: 0.4314 - accuracy: 0.8792 - sparse_categorical_crossentropy: 0.4069\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-14\\assets\n",
      "--- Starting Trial: run-15\n",
      "{'kernel size': 7, 'kernel num': 64, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 1.6548 - accuracy: 0.4437 - sparse_categorical_crossentropy: 1.6021 - val_loss: 0.9544 - val_accuracy: 0.7056 - val_sparse_categorical_crossentropy: 0.9029\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.9118 - accuracy: 0.7003 - sparse_categorical_crossentropy: 0.8617 - val_loss: 0.9594 - val_accuracy: 0.7181 - val_sparse_categorical_crossentropy: 0.9103\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.7889 - accuracy: 0.7417 - sparse_categorical_crossentropy: 0.7396 - val_loss: 0.7408 - val_accuracy: 0.7861 - val_sparse_categorical_crossentropy: 0.6906\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.7178 - accuracy: 0.7698 - sparse_categorical_crossentropy: 0.6673 - val_loss: 0.7451 - val_accuracy: 0.7528 - val_sparse_categorical_crossentropy: 0.6946\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.5945 - accuracy: 0.8079 - sparse_categorical_crossentropy: 0.5435 - val_loss: 0.5800 - val_accuracy: 0.8125 - val_sparse_categorical_crossentropy: 0.5283\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 128s 1s/step - loss: 0.4816 - accuracy: 0.8470 - sparse_categorical_crossentropy: 0.4291 - val_loss: 0.5462 - val_accuracy: 0.8472 - val_sparse_categorical_crossentropy: 0.4931\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 140s 2s/step - loss: 0.4389 - accuracy: 0.8604 - sparse_categorical_crossentropy: 0.3849 - val_loss: 0.5207 - val_accuracy: 0.8528 - val_sparse_categorical_crossentropy: 0.4657\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 152s 2s/step - loss: 0.3364 - accuracy: 0.8995 - sparse_categorical_crossentropy: 0.2817 - val_loss: 0.4745 - val_accuracy: 0.8792 - val_sparse_categorical_crossentropy: 0.4197\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 153s 2s/step - loss: 0.2861 - accuracy: 0.9163 - sparse_categorical_crossentropy: 0.2310 - val_loss: 0.5265 - val_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.4714\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 154s 2s/step - loss: 0.2609 - accuracy: 0.9283 - sparse_categorical_crossentropy: 0.2050 - val_loss: 0.4985 - val_accuracy: 0.8708 - val_sparse_categorical_crossentropy: 0.4425\n",
      "23/23 [==============================] - 5s 200ms/step - loss: 0.4745 - accuracy: 0.8792 - sparse_categorical_crossentropy: 0.4197\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-15\\assets\n",
      "--- Starting Trial: run-16\n",
      "{'kernel size': 7, 'kernel num': 128, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 384s 4s/step - loss: 1.7934 - accuracy: 0.3735 - sparse_categorical_crossentropy: 1.7843 - val_loss: 1.7838 - val_accuracy: 0.1833 - val_sparse_categorical_crossentropy: 1.7733\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 380s 4s/step - loss: 1.7946 - accuracy: 0.3352 - sparse_categorical_crossentropy: 1.7835 - val_loss: 1.5489 - val_accuracy: 0.4444 - val_sparse_categorical_crossentropy: 1.5364\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 377s 4s/step - loss: 1.1531 - accuracy: 0.5754 - sparse_categorical_crossentropy: 1.1389 - val_loss: 0.7599 - val_accuracy: 0.7556 - val_sparse_categorical_crossentropy: 0.7441\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 381s 4s/step - loss: 0.6138 - accuracy: 0.7949 - sparse_categorical_crossentropy: 0.5964 - val_loss: 0.4937 - val_accuracy: 0.8347 - val_sparse_categorical_crossentropy: 0.4748\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 429s 5s/step - loss: 0.4619 - accuracy: 0.8468 - sparse_categorical_crossentropy: 0.4416 - val_loss: 0.4337 - val_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.4122\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 422s 5s/step - loss: 0.3684 - accuracy: 0.8836 - sparse_categorical_crossentropy: 0.3456 - val_loss: 0.5080 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.4842\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 410s 5s/step - loss: 0.2892 - accuracy: 0.9082 - sparse_categorical_crossentropy: 0.2642 - val_loss: 0.4063 - val_accuracy: 0.8736 - val_sparse_categorical_crossentropy: 0.3804\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 398s 4s/step - loss: 0.2331 - accuracy: 0.9331 - sparse_categorical_crossentropy: 0.2063 - val_loss: 0.4593 - val_accuracy: 0.8833 - val_sparse_categorical_crossentropy: 0.4317\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 382s 4s/step - loss: 0.1912 - accuracy: 0.9449 - sparse_categorical_crossentropy: 0.1629 - val_loss: 0.3960 - val_accuracy: 0.8958 - val_sparse_categorical_crossentropy: 0.3668\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 398s 4s/step - loss: 0.1552 - accuracy: 0.9602 - sparse_categorical_crossentropy: 0.1254 - val_loss: 0.4059 - val_accuracy: 0.9014 - val_sparse_categorical_crossentropy: 0.3756\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 380s 4s/step - loss: 0.1315 - accuracy: 0.9690 - sparse_categorical_crossentropy: 0.1006 - val_loss: 0.4198 - val_accuracy: 0.8986 - val_sparse_categorical_crossentropy: 0.3885\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.3960 - accuracy: 0.8958 - sparse_categorical_crossentropy: 0.3668\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-16\\assets\n",
      "--- Starting Trial: run-17\n",
      "{'kernel size': 7, 'kernel num': 128, 'lambda reg': 5e-05}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 336s 4s/step - loss: 2.2144 - accuracy: 0.2947 - sparse_categorical_crossentropy: 2.1815 - val_loss: 1.7701 - val_accuracy: 0.2736 - val_sparse_categorical_crossentropy: 1.7395\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 334s 4s/step - loss: 1.6471 - accuracy: 0.3389 - sparse_categorical_crossentropy: 1.6184 - val_loss: 1.6656 - val_accuracy: 0.3250 - val_sparse_categorical_crossentropy: 1.6387\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 335s 4s/step - loss: 1.5510 - accuracy: 0.3837 - sparse_categorical_crossentropy: 1.5253 - val_loss: 1.7984 - val_accuracy: 0.2153 - val_sparse_categorical_crossentropy: 1.7741\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 348s 4s/step - loss: 1.7784 - accuracy: 0.2304 - sparse_categorical_crossentropy: 1.7549 - val_loss: 1.8155 - val_accuracy: 0.1861 - val_sparse_categorical_crossentropy: 1.7928\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.6656 - accuracy: 0.3250 - sparse_categorical_crossentropy: 1.6387\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-17\\assets\n",
      "--- Starting Trial: run-18\n",
      "{'kernel size': 7, 'kernel num': 128, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "91/91 [==============================] - 387s 4s/step - loss: 2.0048 - accuracy: 0.3179 - sparse_categorical_crossentropy: 1.9426 - val_loss: 1.4508 - val_accuracy: 0.4861 - val_sparse_categorical_crossentropy: 1.3943\n",
      "Epoch 2/15\n",
      "91/91 [==============================] - 387s 4s/step - loss: 1.6275 - accuracy: 0.3787 - sparse_categorical_crossentropy: 1.5768 - val_loss: 1.0341 - val_accuracy: 0.6722 - val_sparse_categorical_crossentropy: 0.9875\n",
      "Epoch 3/15\n",
      "91/91 [==============================] - 387s 4s/step - loss: 1.1980 - accuracy: 0.5901 - sparse_categorical_crossentropy: 1.1539 - val_loss: 0.8516 - val_accuracy: 0.7431 - val_sparse_categorical_crossentropy: 0.8101\n",
      "Epoch 4/15\n",
      "91/91 [==============================] - 397s 4s/step - loss: 0.7620 - accuracy: 0.7616 - sparse_categorical_crossentropy: 0.7212 - val_loss: 0.6620 - val_accuracy: 0.8042 - val_sparse_categorical_crossentropy: 0.6222\n",
      "Epoch 5/15\n",
      "91/91 [==============================] - 418s 5s/step - loss: 0.6204 - accuracy: 0.8093 - sparse_categorical_crossentropy: 0.5812 - val_loss: 0.6106 - val_accuracy: 0.8292 - val_sparse_categorical_crossentropy: 0.5718\n",
      "Epoch 6/15\n",
      "91/91 [==============================] - 388s 4s/step - loss: 0.5587 - accuracy: 0.8228 - sparse_categorical_crossentropy: 0.5195 - val_loss: 0.6244 - val_accuracy: 0.8097 - val_sparse_categorical_crossentropy: 0.5848\n",
      "Epoch 7/15\n",
      "91/91 [==============================] - 387s 4s/step - loss: 0.4854 - accuracy: 0.8420 - sparse_categorical_crossentropy: 0.4455 - val_loss: 0.5333 - val_accuracy: 0.8472 - val_sparse_categorical_crossentropy: 0.4931\n",
      "Epoch 8/15\n",
      "91/91 [==============================] - 385s 4s/step - loss: 0.4266 - accuracy: 0.8607 - sparse_categorical_crossentropy: 0.3856 - val_loss: 0.5051 - val_accuracy: 0.8736 - val_sparse_categorical_crossentropy: 0.4634\n",
      "Epoch 9/15\n",
      "91/91 [==============================] - 351s 4s/step - loss: 0.3780 - accuracy: 0.8825 - sparse_categorical_crossentropy: 0.3359 - val_loss: 0.4953 - val_accuracy: 0.8792 - val_sparse_categorical_crossentropy: 0.4528\n",
      "Epoch 10/15\n",
      "91/91 [==============================] - 346s 4s/step - loss: 0.3550 - accuracy: 0.8915 - sparse_categorical_crossentropy: 0.3122 - val_loss: 0.5803 - val_accuracy: 0.8708 - val_sparse_categorical_crossentropy: 0.5370\n",
      "Epoch 11/15\n",
      "91/91 [==============================] - 367s 4s/step - loss: 0.3368 - accuracy: 0.8943 - sparse_categorical_crossentropy: 0.2931 - val_loss: 0.4499 - val_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.4063\n",
      "Epoch 12/15\n",
      "91/91 [==============================] - 345s 4s/step - loss: 0.2698 - accuracy: 0.9222 - sparse_categorical_crossentropy: 0.2261 - val_loss: 0.5398 - val_accuracy: 0.8764 - val_sparse_categorical_crossentropy: 0.4961\n",
      "Epoch 13/15\n",
      "91/91 [==============================] - 345s 4s/step - loss: 0.2535 - accuracy: 0.9297 - sparse_categorical_crossentropy: 0.2096 - val_loss: 0.5140 - val_accuracy: 0.8847 - val_sparse_categorical_crossentropy: 0.4700\n",
      "23/23 [==============================] - 11s 485ms/step - loss: 0.4499 - accuracy: 0.8861 - sparse_categorical_crossentropy: 0.4063\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Female_L2)\\Run-18\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "for kernel_size in HP_KERNEL_SIZE.domain.values:\n",
    "    for kernel_num in HP_KERNEL_NUM.domain.values:\n",
    "        for lambda_reg in HP_LAMBDA_REG.domain.values:\n",
    "            hparams = {\n",
    "                HP_KERNEL_SIZE : kernel_size,\n",
    "                HP_KERNEL_NUM : kernel_num,\n",
    "                HP_LAMBDA_REG : lambda_reg\n",
    "            }\n",
    "            run_name = f'run-{session_num}'\n",
    "            print('--- Starting Trial:',run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run(\"Logs/Model 1 (Shoes_Female_L2)/hparam_tuning/\" + run_name, hparams, session_num)\n",
    "\n",
    "            session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TF2)",
   "language": "python",
   "name": "python3-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
