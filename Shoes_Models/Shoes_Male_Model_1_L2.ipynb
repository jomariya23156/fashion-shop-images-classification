{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-stranger",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "available-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-function",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "lightweight-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('dataset/Shoes - Male - Train.npz')\n",
    "validation_data = np.load('dataset/Shoes - Male - Validation.npz')\n",
    "test_data = np.load('dataset/Shoes - Male - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fewer-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'labels']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "classified-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = train_data['images'], train_data['labels']\n",
    "images_val, labels_val = validation_data['images'], validation_data['labels']\n",
    "images_test, labels_test = test_data['images'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "arctic-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073, 120, 90, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "higher-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "activated-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# Flip the image by flip the axis 2\n",
    "# we have 4 axis now in images (no. of pic, y, x, channel)\n",
    "# so, if we want to flip horizontally, we flip axis 2\n",
    "\n",
    "flipped_images_train = np.flip(images_train, axis = 2)\n",
    "flipped_images_val = np.flip(images_val, axis = 2)\n",
    "flipped_images_test = np.flip(images_test, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "tutorial-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to concatenate labels with itself, cuz we increase pic in images, so labels have to be increased too.\n",
    "images_train = np.concatenate((images_train, flipped_images_train))\n",
    "labels_train = np.concatenate((labels_train, labels_train))\n",
    "\n",
    "images_val = np.concatenate((images_val, flipped_images_val))\n",
    "labels_val = np.concatenate((labels_val, labels_val))\n",
    "\n",
    "images_test = np.concatenate((images_test, flipped_images_test))\n",
    "labels_test = np.concatenate((labels_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "correct-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 120, 90, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cellular-furniture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "higher-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 120, 90, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "respected-cargo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "angry-drove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dirty-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-tampa",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-cruise",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "clean-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "mature-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_KERNEL_SIZE = hp.HParam('kernel size', hp.Discrete([3,5]))\n",
    "HP_KERNEL_NUM = hp.HParam('kernel num', hp.Discrete([64,128]))\n",
    "HP_LAMBDA_REG = hp.HParam('lambda reg', hp.Discrete([1e-5,1e-4,1e-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "danish-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'logs/Model 1 (Shoes_Male_L2)/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams = [HP_KERNEL_SIZE, HP_KERNEL_NUM, HP_LAMBDA_REG],\n",
    "        metrics = [hp.Metric(METRIC, display_name = 'accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-guest",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cellular-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_KERNEL_NUM], hparams[HP_KERNEL_SIZE], activation = 'relu', input_shape = (120,90,3), kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_KERNEL_NUM], hparams[HP_KERNEL_SIZE], activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.Dense(5, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(name = 'sparse_categorical_crossentropy')\n",
    "    model.compile(optimizer = 'adam', loss = loss_fn, metrics = ['accuracy','sparse_categorical_crossentropy'])\n",
    "    \n",
    "    log_dir = \"Logs\\\\Model 1 (Shoes_Male_L2)\\\\fit\\\\\" + f\"run-{session_num}\"\n",
    "    \n",
    "    # functions for creating confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "        plt.close(figure)\n",
    "\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Define a file writer variable for logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Boots','Trainers/Sneakers','Sandals/Flip flops/Slippers',\n",
    "                                                        'Formal shoes', 'Others'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            \n",
    "    # callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_sparse_categorical_crossentropy', patience = 2, restore_best_weights = True)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1, profile_batch = 0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = log_confusion_matrix)\n",
    "    \n",
    "    model.fit(images_train,\n",
    "              labels_train,\n",
    "              epochs = EPOCHS,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "              validation_data = (images_val, labels_val),\n",
    "              verbose = 1)\n",
    "    \n",
    "    _, accuracy, _ = model.evaluate(images_val, labels_val)\n",
    "    \n",
    "    model.save(r'saved_models\\Model 1 (Shoes_Male_L2)\\Run-{}'.format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acute-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "postal-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Trial: run-1\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 1.1071 - accuracy: 0.6430 - sparse_categorical_crossentropy: 1.1012 - val_loss: 0.5299 - val_accuracy: 0.8108 - val_sparse_categorical_crossentropy: 0.5238\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 0.5188 - accuracy: 0.8128 - sparse_categorical_crossentropy: 0.5125 - val_loss: 0.4210 - val_accuracy: 0.8243 - val_sparse_categorical_crossentropy: 0.4144\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 45s 691ms/step - loss: 0.4154 - accuracy: 0.8521 - sparse_categorical_crossentropy: 0.4086 - val_loss: 0.4794 - val_accuracy: 0.8108 - val_sparse_categorical_crossentropy: 0.4724\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.3717 - accuracy: 0.8642 - sparse_categorical_crossentropy: 0.3644 - val_loss: 0.3940 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.3863\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 0.3133 - accuracy: 0.8929 - sparse_categorical_crossentropy: 0.3054 - val_loss: 0.3911 - val_accuracy: 0.8571 - val_sparse_categorical_crossentropy: 0.3827\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 0.2614 - accuracy: 0.9076 - sparse_categorical_crossentropy: 0.2528 - val_loss: 0.3727 - val_accuracy: 0.8784 - val_sparse_categorical_crossentropy: 0.3637\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 0.2142 - accuracy: 0.9260 - sparse_categorical_crossentropy: 0.2049 - val_loss: 0.4113 - val_accuracy: 0.8803 - val_sparse_categorical_crossentropy: 0.4017\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 0.1852 - accuracy: 0.9349 - sparse_categorical_crossentropy: 0.1753 - val_loss: 0.3780 - val_accuracy: 0.8707 - val_sparse_categorical_crossentropy: 0.3678\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 0.3727 - accuracy: 0.8784 - sparse_categorical_crossentropy: 0.3637\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-1\\assets\n",
      "--- Starting Trial: run-2\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 1.2312 - accuracy: 0.6322 - sparse_categorical_crossentropy: 1.1858 - val_loss: 0.5577 - val_accuracy: 0.8147 - val_sparse_categorical_crossentropy: 0.5129\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 45s 686ms/step - loss: 0.5733 - accuracy: 0.8102 - sparse_categorical_crossentropy: 0.5286 - val_loss: 0.5140 - val_accuracy: 0.8340 - val_sparse_categorical_crossentropy: 0.4692\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.4643 - accuracy: 0.8461 - sparse_categorical_crossentropy: 0.4186 - val_loss: 0.4602 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.4138\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 45s 697ms/step - loss: 0.3989 - accuracy: 0.8818 - sparse_categorical_crossentropy: 0.3521 - val_loss: 0.3996 - val_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.3521\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 49s 746ms/step - loss: 0.3653 - accuracy: 0.8854 - sparse_categorical_crossentropy: 0.3162 - val_loss: 0.3946 - val_accuracy: 0.8649 - val_sparse_categorical_crossentropy: 0.3448\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 0.3161 - accuracy: 0.9038 - sparse_categorical_crossentropy: 0.2655 - val_loss: 0.4163 - val_accuracy: 0.8591 - val_sparse_categorical_crossentropy: 0.3648\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 0.2801 - accuracy: 0.9192 - sparse_categorical_crossentropy: 0.2283 - val_loss: 0.3600 - val_accuracy: 0.8822 - val_sparse_categorical_crossentropy: 0.3078\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 0.2494 - accuracy: 0.9269 - sparse_categorical_crossentropy: 0.1967 - val_loss: 0.3950 - val_accuracy: 0.8707 - val_sparse_categorical_crossentropy: 0.3418\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 50s 763ms/step - loss: 0.2237 - accuracy: 0.9370 - sparse_categorical_crossentropy: 0.1701 - val_loss: 0.3575 - val_accuracy: 0.8822 - val_sparse_categorical_crossentropy: 0.3033\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.2167 - accuracy: 0.9409 - sparse_categorical_crossentropy: 0.1621 - val_loss: 0.3981 - val_accuracy: 0.8919 - val_sparse_categorical_crossentropy: 0.3423\n",
      "Epoch 11/15\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 0.1870 - accuracy: 0.9525 - sparse_categorical_crossentropy: 0.1307 - val_loss: 0.3648 - val_accuracy: 0.8842 - val_sparse_categorical_crossentropy: 0.3083\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 0.3575 - accuracy: 0.8822 - sparse_categorical_crossentropy: 0.3033\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-2\\assets\n",
      "--- Starting Trial: run-3\n",
      "{'kernel size': 3, 'kernel num': 64, 'lambda reg': 0.001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 1.3271 - accuracy: 0.6464 - sparse_categorical_crossentropy: 1.0346 - val_loss: 0.7873 - val_accuracy: 0.8282 - val_sparse_categorical_crossentropy: 0.5343\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 0.7140 - accuracy: 0.8230 - sparse_categorical_crossentropy: 0.4906 - val_loss: 0.6581 - val_accuracy: 0.8514 - val_sparse_categorical_crossentropy: 0.4575\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 0.6121 - accuracy: 0.8480 - sparse_categorical_crossentropy: 0.4247 - val_loss: 0.5405 - val_accuracy: 0.8552 - val_sparse_categorical_crossentropy: 0.3650\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 0.5588 - accuracy: 0.8628 - sparse_categorical_crossentropy: 0.3879 - val_loss: 0.5562 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.3879\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 0.5216 - accuracy: 0.8717 - sparse_categorical_crossentropy: 0.3563 - val_loss: 0.5630 - val_accuracy: 0.8494 - val_sparse_categorical_crossentropy: 0.3991\n",
      "17/17 [==============================] - 2s 93ms/step - loss: 0.5405 - accuracy: 0.8552 - sparse_categorical_crossentropy: 0.3650\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-3\\assets\n",
      "--- Starting Trial: run-4\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 112s 2s/step - loss: 1.2594 - accuracy: 0.6288 - sparse_categorical_crossentropy: 1.2524 - val_loss: 0.5400 - val_accuracy: 0.8127 - val_sparse_categorical_crossentropy: 0.5331\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.5202 - accuracy: 0.8150 - sparse_categorical_crossentropy: 0.5133 - val_loss: 0.3937 - val_accuracy: 0.8649 - val_sparse_categorical_crossentropy: 0.3866\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 111s 2s/step - loss: 0.4177 - accuracy: 0.8550 - sparse_categorical_crossentropy: 0.4105 - val_loss: 0.3788 - val_accuracy: 0.8591 - val_sparse_categorical_crossentropy: 0.3715\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.3523 - accuracy: 0.8758 - sparse_categorical_crossentropy: 0.3448 - val_loss: 0.4315 - val_accuracy: 0.8359 - val_sparse_categorical_crossentropy: 0.4238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "65/65 [==============================] - 122s 2s/step - loss: 0.3064 - accuracy: 0.8871 - sparse_categorical_crossentropy: 0.2986 - val_loss: 0.3963 - val_accuracy: 0.8552 - val_sparse_categorical_crossentropy: 0.3883\n",
      "17/17 [==============================] - 4s 218ms/step - loss: 0.3788 - accuracy: 0.8591 - sparse_categorical_crossentropy: 0.3715\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-4\\assets\n",
      "--- Starting Trial: run-5\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 112s 2s/step - loss: 1.3718 - accuracy: 0.6141 - sparse_categorical_crossentropy: 1.3128 - val_loss: 0.5743 - val_accuracy: 0.8243 - val_sparse_categorical_crossentropy: 0.5178\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 113s 2s/step - loss: 0.6017 - accuracy: 0.8022 - sparse_categorical_crossentropy: 0.5482 - val_loss: 0.5496 - val_accuracy: 0.8031 - val_sparse_categorical_crossentropy: 0.4987\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.5081 - accuracy: 0.8321 - sparse_categorical_crossentropy: 0.4581 - val_loss: 0.4744 - val_accuracy: 0.8263 - val_sparse_categorical_crossentropy: 0.4256\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 106s 2s/step - loss: 0.4314 - accuracy: 0.8553 - sparse_categorical_crossentropy: 0.3835 - val_loss: 0.4218 - val_accuracy: 0.8514 - val_sparse_categorical_crossentropy: 0.3747\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 109s 2s/step - loss: 0.3802 - accuracy: 0.8799 - sparse_categorical_crossentropy: 0.3331 - val_loss: 0.4381 - val_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.3910\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 132s 2s/step - loss: 0.3654 - accuracy: 0.8830 - sparse_categorical_crossentropy: 0.3179 - val_loss: 0.4436 - val_accuracy: 0.8494 - val_sparse_categorical_crossentropy: 0.3959\n",
      "17/17 [==============================] - 4s 245ms/step - loss: 0.4218 - accuracy: 0.8514 - sparse_categorical_crossentropy: 0.3747\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-5\\assets\n",
      "--- Starting Trial: run-6\n",
      "{'kernel size': 3, 'kernel num': 128, 'lambda reg': 0.001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 115s 2s/step - loss: 1.5431 - accuracy: 0.5950 - sparse_categorical_crossentropy: 1.1723 - val_loss: 0.8607 - val_accuracy: 0.8185 - val_sparse_categorical_crossentropy: 0.5829\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.8230 - accuracy: 0.7832 - sparse_categorical_crossentropy: 0.5896 - val_loss: 0.6411 - val_accuracy: 0.8320 - val_sparse_categorical_crossentropy: 0.4368\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 113s 2s/step - loss: 0.6344 - accuracy: 0.8370 - sparse_categorical_crossentropy: 0.4507 - val_loss: 0.6602 - val_accuracy: 0.8205 - val_sparse_categorical_crossentropy: 0.4926\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.5845 - accuracy: 0.8480 - sparse_categorical_crossentropy: 0.4214 - val_loss: 0.5165 - val_accuracy: 0.8745 - val_sparse_categorical_crossentropy: 0.3597\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.4942 - accuracy: 0.8775 - sparse_categorical_crossentropy: 0.3435 - val_loss: 0.5196 - val_accuracy: 0.8571 - val_sparse_categorical_crossentropy: 0.3706\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.4915 - accuracy: 0.8765 - sparse_categorical_crossentropy: 0.3465 - val_loss: 0.5436 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.3991\n",
      "17/17 [==============================] - 4s 215ms/step - loss: 0.5165 - accuracy: 0.8745 - sparse_categorical_crossentropy: 0.3597\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-6\\assets\n",
      "--- Starting Trial: run-7\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 78s 1s/step - loss: 0.9250 - accuracy: 0.6553 - sparse_categorical_crossentropy: 0.9192 - val_loss: 0.6174 - val_accuracy: 0.7703 - val_sparse_categorical_crossentropy: 0.6116\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 75s 1s/step - loss: 0.5828 - accuracy: 0.7906 - sparse_categorical_crossentropy: 0.5768 - val_loss: 0.4780 - val_accuracy: 0.8475 - val_sparse_categorical_crossentropy: 0.4718\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.4538 - accuracy: 0.8418 - sparse_categorical_crossentropy: 0.4474 - val_loss: 0.3967 - val_accuracy: 0.8552 - val_sparse_categorical_crossentropy: 0.3901\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.3578 - accuracy: 0.8748 - sparse_categorical_crossentropy: 0.3509 - val_loss: 0.3567 - val_accuracy: 0.8533 - val_sparse_categorical_crossentropy: 0.3497\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 74s 1s/step - loss: 0.3018 - accuracy: 0.8895 - sparse_categorical_crossentropy: 0.2944 - val_loss: 0.3664 - val_accuracy: 0.8687 - val_sparse_categorical_crossentropy: 0.3588\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.2527 - accuracy: 0.9110 - sparse_categorical_crossentropy: 0.2449 - val_loss: 0.3780 - val_accuracy: 0.8687 - val_sparse_categorical_crossentropy: 0.3701\n",
      "17/17 [==============================] - 2s 132ms/step - loss: 0.3567 - accuracy: 0.8533 - sparse_categorical_crossentropy: 0.3497\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-7\\assets\n",
      "--- Starting Trial: run-8\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 74s 1s/step - loss: 1.2599 - accuracy: 0.5813 - sparse_categorical_crossentropy: 1.2147 - val_loss: 0.7867 - val_accuracy: 0.7317 - val_sparse_categorical_crossentropy: 0.7446\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.6912 - accuracy: 0.7685 - sparse_categorical_crossentropy: 0.6511 - val_loss: 0.5514 - val_accuracy: 0.8263 - val_sparse_categorical_crossentropy: 0.5127\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.5394 - accuracy: 0.8220 - sparse_categorical_crossentropy: 0.5020 - val_loss: 0.5180 - val_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.4816\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.4942 - accuracy: 0.8333 - sparse_categorical_crossentropy: 0.4584 - val_loss: 0.4258 - val_accuracy: 0.8398 - val_sparse_categorical_crossentropy: 0.3906\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 70s 1s/step - loss: 0.4256 - accuracy: 0.8601 - sparse_categorical_crossentropy: 0.3908 - val_loss: 0.4486 - val_accuracy: 0.8359 - val_sparse_categorical_crossentropy: 0.4144\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.3888 - accuracy: 0.8736 - sparse_categorical_crossentropy: 0.3548 - val_loss: 0.3937 - val_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.3598\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.3543 - accuracy: 0.8775 - sparse_categorical_crossentropy: 0.3203 - val_loss: 0.3793 - val_accuracy: 0.8745 - val_sparse_categorical_crossentropy: 0.3451\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 73s 1s/step - loss: 0.3178 - accuracy: 0.8973 - sparse_categorical_crossentropy: 0.2835 - val_loss: 0.3526 - val_accuracy: 0.8803 - val_sparse_categorical_crossentropy: 0.3184\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 80s 1s/step - loss: 0.2927 - accuracy: 0.9035 - sparse_categorical_crossentropy: 0.2582 - val_loss: 0.4502 - val_accuracy: 0.8687 - val_sparse_categorical_crossentropy: 0.4151\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.2712 - accuracy: 0.9144 - sparse_categorical_crossentropy: 0.2357 - val_loss: 0.3953 - val_accuracy: 0.8726 - val_sparse_categorical_crossentropy: 0.3594\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 0.3526 - accuracy: 0.8803 - sparse_categorical_crossentropy: 0.3184\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-8\\assets\n",
      "--- Starting Trial: run-9\n",
      "{'kernel size': 5, 'kernel num': 64, 'lambda reg': 0.001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 73s 1s/step - loss: 1.6045 - accuracy: 0.5989 - sparse_categorical_crossentropy: 1.2722 - val_loss: 0.8732 - val_accuracy: 0.7896 - val_sparse_categorical_crossentropy: 0.6103\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.8115 - accuracy: 0.7935 - sparse_categorical_crossentropy: 0.5832 - val_loss: 0.6526 - val_accuracy: 0.8436 - val_sparse_categorical_crossentropy: 0.4524\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.6518 - accuracy: 0.8309 - sparse_categorical_crossentropy: 0.4706 - val_loss: 0.7098 - val_accuracy: 0.7876 - val_sparse_categorical_crossentropy: 0.5435\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.6477 - accuracy: 0.8210 - sparse_categorical_crossentropy: 0.4878 - val_loss: 0.5869 - val_accuracy: 0.8301 - val_sparse_categorical_crossentropy: 0.4366\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 74s 1s/step - loss: 0.5661 - accuracy: 0.8493 - sparse_categorical_crossentropy: 0.4229 - val_loss: 0.5424 - val_accuracy: 0.8378 - val_sparse_categorical_crossentropy: 0.4055\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 72s 1s/step - loss: 0.5208 - accuracy: 0.8579 - sparse_categorical_crossentropy: 0.3890 - val_loss: 0.5387 - val_accuracy: 0.8359 - val_sparse_categorical_crossentropy: 0.4103\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 60s 928ms/step - loss: 0.4985 - accuracy: 0.8693 - sparse_categorical_crossentropy: 0.3704 - val_loss: 0.4835 - val_accuracy: 0.8533 - val_sparse_categorical_crossentropy: 0.3556\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 60s 925ms/step - loss: 0.4215 - accuracy: 0.8934 - sparse_categorical_crossentropy: 0.2965 - val_loss: 0.5146 - val_accuracy: 0.8514 - val_sparse_categorical_crossentropy: 0.3909\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 60s 929ms/step - loss: 0.4095 - accuracy: 0.8939 - sparse_categorical_crossentropy: 0.2862 - val_loss: 0.4825 - val_accuracy: 0.8668 - val_sparse_categorical_crossentropy: 0.3592\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4835 - accuracy: 0.8533 - sparse_categorical_crossentropy: 0.3556\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-9\\assets\n",
      "--- Starting Trial: run-10\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 1e-05}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 154s 2s/step - loss: 1.4513 - accuracy: 0.5323 - sparse_categorical_crossentropy: 1.4441 - val_loss: 0.7213 - val_accuracy: 0.7471 - val_sparse_categorical_crossentropy: 0.7140\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 158s 2s/step - loss: 0.7190 - accuracy: 0.7463 - sparse_categorical_crossentropy: 0.7118 - val_loss: 0.5624 - val_accuracy: 0.8069 - val_sparse_categorical_crossentropy: 0.5552\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 168s 3s/step - loss: 0.5346 - accuracy: 0.8150 - sparse_categorical_crossentropy: 0.5275 - val_loss: 0.4312 - val_accuracy: 0.8475 - val_sparse_categorical_crossentropy: 0.4241\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 180s 3s/step - loss: 0.4908 - accuracy: 0.8259 - sparse_categorical_crossentropy: 0.4836 - val_loss: 0.4421 - val_accuracy: 0.8320 - val_sparse_categorical_crossentropy: 0.4348\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 162s 2s/step - loss: 0.4437 - accuracy: 0.8377 - sparse_categorical_crossentropy: 0.4364 - val_loss: 0.4138 - val_accuracy: 0.8398 - val_sparse_categorical_crossentropy: 0.4065\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 156s 2s/step - loss: 0.3908 - accuracy: 0.8582 - sparse_categorical_crossentropy: 0.3834 - val_loss: 0.4150 - val_accuracy: 0.8494 - val_sparse_categorical_crossentropy: 0.4076\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 143s 2s/step - loss: 0.3322 - accuracy: 0.8777 - sparse_categorical_crossentropy: 0.3247 - val_loss: 0.3782 - val_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.3706\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 144s 2s/step - loss: 0.2903 - accuracy: 0.8968 - sparse_categorical_crossentropy: 0.2826 - val_loss: 0.4522 - val_accuracy: 0.8456 - val_sparse_categorical_crossentropy: 0.4444\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 146s 2s/step - loss: 0.2838 - accuracy: 0.8951 - sparse_categorical_crossentropy: 0.2759 - val_loss: 0.4187 - val_accuracy: 0.8475 - val_sparse_categorical_crossentropy: 0.4106\n",
      "17/17 [==============================] - 7s 420ms/step - loss: 0.3782 - accuracy: 0.8610 - sparse_categorical_crossentropy: 0.3706\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-10\\assets\n",
      "--- Starting Trial: run-11\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 0.0001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 170s 3s/step - loss: 1.6016 - accuracy: 0.5861 - sparse_categorical_crossentropy: 1.5435 - val_loss: 0.6783 - val_accuracy: 0.7876 - val_sparse_categorical_crossentropy: 0.6241\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 187s 3s/step - loss: 0.6921 - accuracy: 0.7750 - sparse_categorical_crossentropy: 0.6421 - val_loss: 0.6188 - val_accuracy: 0.7954 - val_sparse_categorical_crossentropy: 0.5719\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 203s 3s/step - loss: 0.5980 - accuracy: 0.7935 - sparse_categorical_crossentropy: 0.5536 - val_loss: 0.5339 - val_accuracy: 0.8089 - val_sparse_categorical_crossentropy: 0.4918\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 211s 3s/step - loss: 0.5351 - accuracy: 0.8177 - sparse_categorical_crossentropy: 0.4946 - val_loss: 0.4708 - val_accuracy: 0.8475 - val_sparse_categorical_crossentropy: 0.4318\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 221s 3s/step - loss: 0.4718 - accuracy: 0.8456 - sparse_categorical_crossentropy: 0.4338 - val_loss: 0.4718 - val_accuracy: 0.8263 - val_sparse_categorical_crossentropy: 0.4349\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 203s 3s/step - loss: 0.4279 - accuracy: 0.8620 - sparse_categorical_crossentropy: 0.3914 - val_loss: 0.4331 - val_accuracy: 0.8514 - val_sparse_categorical_crossentropy: 0.3970\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 196s 3s/step - loss: 0.3797 - accuracy: 0.8755 - sparse_categorical_crossentropy: 0.3443 - val_loss: 0.4568 - val_accuracy: 0.8436 - val_sparse_categorical_crossentropy: 0.4221\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 207s 3s/step - loss: 0.3477 - accuracy: 0.8922 - sparse_categorical_crossentropy: 0.3134 - val_loss: 0.4192 - val_accuracy: 0.8552 - val_sparse_categorical_crossentropy: 0.3853\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 205s 3s/step - loss: 0.2917 - accuracy: 0.9064 - sparse_categorical_crossentropy: 0.2581 - val_loss: 0.3455 - val_accuracy: 0.8745 - val_sparse_categorical_crossentropy: 0.3122\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 198s 3s/step - loss: 0.2988 - accuracy: 0.9016 - sparse_categorical_crossentropy: 0.2656 - val_loss: 0.4044 - val_accuracy: 0.8571 - val_sparse_categorical_crossentropy: 0.3711\n",
      "Epoch 11/15\n",
      "65/65 [==============================] - 199s 3s/step - loss: 0.2652 - accuracy: 0.9115 - sparse_categorical_crossentropy: 0.2318 - val_loss: 0.3587 - val_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.3252\n",
      "17/17 [==============================] - 7s 430ms/step - loss: 0.3455 - accuracy: 0.8745 - sparse_categorical_crossentropy: 0.3122\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-11\\assets\n",
      "--- Starting Trial: run-12\n",
      "{'kernel size': 5, 'kernel num': 128, 'lambda reg': 0.001}\n",
      "Epoch 1/15\n",
      "65/65 [==============================] - 204s 3s/step - loss: 1.7157 - accuracy: 0.5622 - sparse_categorical_crossentropy: 1.3588 - val_loss: 0.9136 - val_accuracy: 0.7625 - val_sparse_categorical_crossentropy: 0.6381\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 226s 3s/step - loss: 0.8800 - accuracy: 0.7689 - sparse_categorical_crossentropy: 0.6459 - val_loss: 0.7451 - val_accuracy: 0.7915 - val_sparse_categorical_crossentropy: 0.5405\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 222s 3s/step - loss: 0.7134 - accuracy: 0.8090 - sparse_categorical_crossentropy: 0.5262 - val_loss: 0.6911 - val_accuracy: 0.7934 - val_sparse_categorical_crossentropy: 0.5207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "65/65 [==============================] - 220s 3s/step - loss: 0.6410 - accuracy: 0.8285 - sparse_categorical_crossentropy: 0.4794 - val_loss: 0.7659 - val_accuracy: 0.7606 - val_sparse_categorical_crossentropy: 0.6108\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 207s 3s/step - loss: 0.5704 - accuracy: 0.8497 - sparse_categorical_crossentropy: 0.4209 - val_loss: 0.5635 - val_accuracy: 0.8456 - val_sparse_categorical_crossentropy: 0.4227\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 219s 3s/step - loss: 0.5250 - accuracy: 0.8591 - sparse_categorical_crossentropy: 0.3901 - val_loss: 0.5989 - val_accuracy: 0.8127 - val_sparse_categorical_crossentropy: 0.4683\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 215s 3s/step - loss: 0.4860 - accuracy: 0.8688 - sparse_categorical_crossentropy: 0.3585 - val_loss: 0.5617 - val_accuracy: 0.8320 - val_sparse_categorical_crossentropy: 0.4370\n",
      "17/17 [==============================] - 6s 382ms/step - loss: 0.5635 - accuracy: 0.8456 - sparse_categorical_crossentropy: 0.4227\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 1 (Shoes_Male_L2)\\Run-12\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "for kernel_size in HP_KERNEL_SIZE.domain.values:\n",
    "    for kernel_num in HP_KERNEL_NUM.domain.values:\n",
    "        for lambda_reg in HP_LAMBDA_REG.domain.values:\n",
    "            hparams = {\n",
    "                HP_KERNEL_SIZE : kernel_size,\n",
    "                HP_KERNEL_NUM : kernel_num,\n",
    "                HP_LAMBDA_REG : lambda_reg\n",
    "            }\n",
    "            run_name = f'run-{session_num}'\n",
    "            print('--- Starting Trial:',run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run(\"Logs/Model 1 (Shoes_Male_L2)/hparam_tuning/\" + run_name, hparams, session_num)\n",
    "\n",
    "            session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TF2)",
   "language": "python",
   "name": "python3-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
