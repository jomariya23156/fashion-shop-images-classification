{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passing-vegetarian",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "annoying-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-accounting",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "progressive-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('dataset/Trousers & Jeans - All - Train.npz')\n",
    "validation_data = np.load('dataset/Trousers & Jeans - All - Validation.npz')\n",
    "test_data = np.load('dataset/Trousers & Jeans - All - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "affected-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'labels', 'genders']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "available-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = train_data['images'], train_data['labels']\n",
    "images_val, labels_val = validation_data['images'], validation_data['labels']\n",
    "images_test, labels_test = test_data['images'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dress-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "thirty-liberty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4004, 120, 90, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "personal-reservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4004,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aquatic-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 120, 90, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "textile-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "innocent-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 120, 90, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "injured-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "first-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize \n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-boost",
   "metadata": {},
   "source": [
    "## Create the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-flush",
   "metadata": {},
   "source": [
    "### Define hyparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "colored-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "indirect-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LAMBDA = hp.HParam('lambda', hp.Discrete([1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "written-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'logs/Model 4 (Trousers&Jeans_All_L2)/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams = [HP_LAMBDA],\n",
    "        metrics = [hp.Metric(METRIC, display_name='accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-service",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "robust-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, session_num):\n",
    "    model = tf.keras.Sequential([\n",
    "        # we choose the valueus for kernel_num, kernel_size, and dense from the best of the hyperparameter tuning we do in model 3\n",
    "        tf.keras.layers.Conv2D(96, 7, activation = 'relu', input_shape = (120,90,3), kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(96, 3, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(hparams[HP_LAMBDA])),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(name = 'sparse_categorical_crossentropy')\n",
    "    model.compile(optimizer = 'adam', loss = loss_fn, metrics = ['accuracy','sparse_categorical_crossentropy'])\n",
    "    \n",
    "    log_dir = \"Logs\\\\Model 4 (Trousers&Jeans_All_L2)\\\\fit\\\\\" + f\"run-{session_num}\"\n",
    "    \n",
    "    # functions for creating confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "        plt.close(figure)\n",
    "\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Define a file writer variable for logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Trousers Male','Jeans Male','Trousers Female','Jeans Female'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            \n",
    "    # callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_sparse_categorical_crossentropy', patience = 2, restore_best_weights = True)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = log_confusion_matrix)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq = 1, profile_batch = 0)\n",
    "    \n",
    "    model.fit(images_train,\n",
    "              labels_train,\n",
    "              epochs = EPOCHS,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "              validation_data = (images_val, labels_val),\n",
    "              verbose = 1)\n",
    "    \n",
    "    _, accuracy, _ = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    model.save(r'saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-{}'.format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "junior-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir, hparams, session_num):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "arranged-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Trial: run-1\n",
      "{'lambda': 1e-05}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.5289 - accuracy: 0.4743 - sparse_categorical_crossentropy: 1.5171 - val_loss: 1.0400 - val_accuracy: 0.5700 - val_sparse_categorical_crossentropy: 1.0286\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.9390 - accuracy: 0.6184 - sparse_categorical_crossentropy: 0.9278 - val_loss: 0.9707 - val_accuracy: 0.6000 - val_sparse_categorical_crossentropy: 0.9597\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 80s 1s/step - loss: 0.8322 - accuracy: 0.6611 - sparse_categorical_crossentropy: 0.8211 - val_loss: 0.8807 - val_accuracy: 0.6480 - val_sparse_categorical_crossentropy: 0.8696\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7628 - accuracy: 0.6908 - sparse_categorical_crossentropy: 0.7515 - val_loss: 0.8778 - val_accuracy: 0.6500 - val_sparse_categorical_crossentropy: 0.8662\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7275 - accuracy: 0.7120 - sparse_categorical_crossentropy: 0.7157 - val_loss: 0.8637 - val_accuracy: 0.6480 - val_sparse_categorical_crossentropy: 0.8518\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.6694 - accuracy: 0.7305 - sparse_categorical_crossentropy: 0.6572 - val_loss: 0.8508 - val_accuracy: 0.6760 - val_sparse_categorical_crossentropy: 0.8384\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.6179 - accuracy: 0.7527 - sparse_categorical_crossentropy: 0.6053 - val_loss: 0.7340 - val_accuracy: 0.7160 - val_sparse_categorical_crossentropy: 0.7212\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.5747 - accuracy: 0.7722 - sparse_categorical_crossentropy: 0.5617 - val_loss: 0.8501 - val_accuracy: 0.6820 - val_sparse_categorical_crossentropy: 0.8369\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.5571 - accuracy: 0.7847 - sparse_categorical_crossentropy: 0.5437 - val_loss: 0.7167 - val_accuracy: 0.7480 - val_sparse_categorical_crossentropy: 0.7030\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 74s 1s/step - loss: 0.5094 - accuracy: 0.7990 - sparse_categorical_crossentropy: 0.4954 - val_loss: 0.7222 - val_accuracy: 0.7400 - val_sparse_categorical_crossentropy: 0.7078\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 74s 1s/step - loss: 0.4917 - accuracy: 0.8079 - sparse_categorical_crossentropy: 0.4769 - val_loss: 0.7685 - val_accuracy: 0.7100 - val_sparse_categorical_crossentropy: 0.7534\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.7167 - accuracy: 0.7480 - sparse_categorical_crossentropy: 0.7030\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\Python3-TF2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-1\\assets\n",
      "--- Starting Trial: run-2\n",
      "{'lambda': 5e-05}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 1.3781 - accuracy: 0.4573 - sparse_categorical_crossentropy: 1.3273 - val_loss: 1.1516 - val_accuracy: 0.5260 - val_sparse_categorical_crossentropy: 1.1042\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.9514 - accuracy: 0.6289 - sparse_categorical_crossentropy: 0.9080 - val_loss: 0.9835 - val_accuracy: 0.6340 - val_sparse_categorical_crossentropy: 0.9435\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.8582 - accuracy: 0.6618 - sparse_categorical_crossentropy: 0.8199 - val_loss: 1.0108 - val_accuracy: 0.5980 - val_sparse_categorical_crossentropy: 0.9740\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7827 - accuracy: 0.6926 - sparse_categorical_crossentropy: 0.7471 - val_loss: 0.8678 - val_accuracy: 0.6600 - val_sparse_categorical_crossentropy: 0.8329\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.7417 - accuracy: 0.7100 - sparse_categorical_crossentropy: 0.7070 - val_loss: 0.8616 - val_accuracy: 0.6760 - val_sparse_categorical_crossentropy: 0.8273\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 0.6872 - accuracy: 0.7368 - sparse_categorical_crossentropy: 0.6530 - val_loss: 0.8817 - val_accuracy: 0.6440 - val_sparse_categorical_crossentropy: 0.8472\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 82s 1s/step - loss: 0.6628 - accuracy: 0.7430 - sparse_categorical_crossentropy: 0.6284 - val_loss: 0.8312 - val_accuracy: 0.6920 - val_sparse_categorical_crossentropy: 0.7969\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 83s 1s/step - loss: 0.6154 - accuracy: 0.7612 - sparse_categorical_crossentropy: 0.5809 - val_loss: 0.8133 - val_accuracy: 0.7100 - val_sparse_categorical_crossentropy: 0.7785\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 80s 1s/step - loss: 0.5858 - accuracy: 0.7810 - sparse_categorical_crossentropy: 0.5509 - val_loss: 0.7745 - val_accuracy: 0.7040 - val_sparse_categorical_crossentropy: 0.7392\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 0.5604 - accuracy: 0.7892 - sparse_categorical_crossentropy: 0.5243 - val_loss: 0.7870 - val_accuracy: 0.7320 - val_sparse_categorical_crossentropy: 0.7504\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5260 - accuracy: 0.8037 - sparse_categorical_crossentropy: 0.4887 - val_loss: 0.7585 - val_accuracy: 0.7380 - val_sparse_categorical_crossentropy: 0.7194\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 80s 1s/step - loss: 0.5138 - accuracy: 0.8049 - sparse_categorical_crossentropy: 0.4735 - val_loss: 0.8217 - val_accuracy: 0.7340 - val_sparse_categorical_crossentropy: 0.7803\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 0.4768 - accuracy: 0.8254 - sparse_categorical_crossentropy: 0.4351 - val_loss: 0.7740 - val_accuracy: 0.7280 - val_sparse_categorical_crossentropy: 0.7320\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.7585 - accuracy: 0.7380 - sparse_categorical_crossentropy: 0.7194\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-2\\assets\n",
      "--- Starting Trial: run-3\n",
      "{'lambda': 0.0001}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 83s 1s/step - loss: 1.5594 - accuracy: 0.4510 - sparse_categorical_crossentropy: 1.4833 - val_loss: 1.1954 - val_accuracy: 0.5180 - val_sparse_categorical_crossentropy: 1.1305\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 84s 1s/step - loss: 0.9952 - accuracy: 0.6129 - sparse_categorical_crossentropy: 0.9372 - val_loss: 1.0414 - val_accuracy: 0.6000 - val_sparse_categorical_crossentropy: 0.9892\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.9052 - accuracy: 0.6424 - sparse_categorical_crossentropy: 0.8560 - val_loss: 0.9407 - val_accuracy: 0.6400 - val_sparse_categorical_crossentropy: 0.8943\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.7979 - accuracy: 0.6988 - sparse_categorical_crossentropy: 0.7537 - val_loss: 0.9108 - val_accuracy: 0.6360 - val_sparse_categorical_crossentropy: 0.8682\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 82s 1s/step - loss: 0.7391 - accuracy: 0.7133 - sparse_categorical_crossentropy: 0.6973 - val_loss: 0.9018 - val_accuracy: 0.6560 - val_sparse_categorical_crossentropy: 0.8605\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.6976 - accuracy: 0.7368 - sparse_categorical_crossentropy: 0.6565 - val_loss: 0.8101 - val_accuracy: 0.6880 - val_sparse_categorical_crossentropy: 0.7670\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 83s 1s/step - loss: 0.6684 - accuracy: 0.7455 - sparse_categorical_crossentropy: 0.6240 - val_loss: 0.7968 - val_accuracy: 0.6960 - val_sparse_categorical_crossentropy: 0.7526\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.6406 - accuracy: 0.7537 - sparse_categorical_crossentropy: 0.5965 - val_loss: 0.8101 - val_accuracy: 0.7140 - val_sparse_categorical_crossentropy: 0.7662\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.6241 - accuracy: 0.7672 - sparse_categorical_crossentropy: 0.5788 - val_loss: 0.8010 - val_accuracy: 0.7040 - val_sparse_categorical_crossentropy: 0.7543\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.7968 - accuracy: 0.6960 - sparse_categorical_crossentropy: 0.7526\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-3\\assets\n",
      "--- Starting Trial: run-4\n",
      "{'lambda': 0.0005}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 1.9232 - accuracy: 0.4523 - sparse_categorical_crossentropy: 1.5593 - val_loss: 1.3380 - val_accuracy: 0.5560 - val_sparse_categorical_crossentropy: 1.0490\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 1.1594 - accuracy: 0.6209 - sparse_categorical_crossentropy: 0.9155 - val_loss: 1.3018 - val_accuracy: 0.5360 - val_sparse_categorical_crossentropy: 1.0940\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.0185 - accuracy: 0.6531 - sparse_categorical_crossentropy: 0.8309 - val_loss: 1.1041 - val_accuracy: 0.6200 - val_sparse_categorical_crossentropy: 0.9367\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.9222 - accuracy: 0.6796 - sparse_categorical_crossentropy: 0.7674 - val_loss: 0.9752 - val_accuracy: 0.6780 - val_sparse_categorical_crossentropy: 0.8320\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.8592 - accuracy: 0.7005 - sparse_categorical_crossentropy: 0.7235 - val_loss: 0.9660 - val_accuracy: 0.6560 - val_sparse_categorical_crossentropy: 0.8364\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 0.8233 - accuracy: 0.7188 - sparse_categorical_crossentropy: 0.6972 - val_loss: 0.8945 - val_accuracy: 0.6720 - val_sparse_categorical_crossentropy: 0.7741\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7715 - accuracy: 0.7355 - sparse_categorical_crossentropy: 0.6539 - val_loss: 0.9451 - val_accuracy: 0.6820 - val_sparse_categorical_crossentropy: 0.8287\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 0.7642 - accuracy: 0.7345 - sparse_categorical_crossentropy: 0.6496 - val_loss: 0.9344 - val_accuracy: 0.6840 - val_sparse_categorical_crossentropy: 0.8214\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.8945 - accuracy: 0.6720 - sparse_categorical_crossentropy: 0.7741\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-4\\assets\n",
      "--- Starting Trial: run-5\n",
      "{'lambda': 0.001}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 2.2620 - accuracy: 0.4381 - sparse_categorical_crossentropy: 1.6426 - val_loss: 1.5655 - val_accuracy: 0.5260 - val_sparse_categorical_crossentropy: 1.1206\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 1.3284 - accuracy: 0.6109 - sparse_categorical_crossentropy: 0.9615 - val_loss: 1.2753 - val_accuracy: 0.6040 - val_sparse_categorical_crossentropy: 0.9720\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 1.1427 - accuracy: 0.6374 - sparse_categorical_crossentropy: 0.8767 - val_loss: 1.1278 - val_accuracy: 0.6480 - val_sparse_categorical_crossentropy: 0.8952\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 0.9979 - accuracy: 0.6846 - sparse_categorical_crossentropy: 0.7876 - val_loss: 1.0583 - val_accuracy: 0.6580 - val_sparse_categorical_crossentropy: 0.8682\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 0.9665 - accuracy: 0.6811 - sparse_categorical_crossentropy: 0.7914 - val_loss: 1.0020 - val_accuracy: 0.6600 - val_sparse_categorical_crossentropy: 0.8388\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.8747 - accuracy: 0.7093 - sparse_categorical_crossentropy: 0.7172 - val_loss: 0.9499 - val_accuracy: 0.6720 - val_sparse_categorical_crossentropy: 0.8015\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.8116 - accuracy: 0.7215 - sparse_categorical_crossentropy: 0.6723 - val_loss: 0.9437 - val_accuracy: 0.6980 - val_sparse_categorical_crossentropy: 0.8109\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.8094 - accuracy: 0.7153 - sparse_categorical_crossentropy: 0.6794 - val_loss: 0.9111 - val_accuracy: 0.6800 - val_sparse_categorical_crossentropy: 0.7831\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7454 - accuracy: 0.7420 - sparse_categorical_crossentropy: 0.6198 - val_loss: 0.8574 - val_accuracy: 0.7020 - val_sparse_categorical_crossentropy: 0.7357\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7176 - accuracy: 0.7595 - sparse_categorical_crossentropy: 0.5954 - val_loss: 0.8968 - val_accuracy: 0.6960 - val_sparse_categorical_crossentropy: 0.7666\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7062 - accuracy: 0.7675 - sparse_categorical_crossentropy: 0.5784 - val_loss: 0.8512 - val_accuracy: 0.7140 - val_sparse_categorical_crossentropy: 0.7241\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.6881 - accuracy: 0.7752 - sparse_categorical_crossentropy: 0.5583 - val_loss: 0.8874 - val_accuracy: 0.6820 - val_sparse_categorical_crossentropy: 0.7611\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 0.6551 - accuracy: 0.7917 - sparse_categorical_crossentropy: 0.5284 - val_loss: 0.8308 - val_accuracy: 0.7100 - val_sparse_categorical_crossentropy: 0.7051\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 80s 1s/step - loss: 0.6254 - accuracy: 0.8014 - sparse_categorical_crossentropy: 0.5001 - val_loss: 0.8961 - val_accuracy: 0.6980 - val_sparse_categorical_crossentropy: 0.7702\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.6208 - accuracy: 0.8032 - sparse_categorical_crossentropy: 0.4907 - val_loss: 0.8611 - val_accuracy: 0.6780 - val_sparse_categorical_crossentropy: 0.7330\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.8308 - accuracy: 0.7100 - sparse_categorical_crossentropy: 0.7051\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-5\\assets\n",
      "--- Starting Trial: run-6\n",
      "{'lambda': 0.005}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 86s 1s/step - loss: 3.4903 - accuracy: 0.4508 - sparse_categorical_crossentropy: 1.6412 - val_loss: 1.9713 - val_accuracy: 0.5200 - val_sparse_categorical_crossentropy: 1.1184\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 1.6091 - accuracy: 0.5819 - sparse_categorical_crossentropy: 1.0051 - val_loss: 1.4950 - val_accuracy: 0.5460 - val_sparse_categorical_crossentropy: 1.0331\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 82s 1s/step - loss: 1.3167 - accuracy: 0.6201 - sparse_categorical_crossentropy: 0.9381 - val_loss: 1.2792 - val_accuracy: 0.5940 - val_sparse_categorical_crossentropy: 0.9671\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 85s 1s/step - loss: 1.1612 - accuracy: 0.6391 - sparse_categorical_crossentropy: 0.8699 - val_loss: 1.2167 - val_accuracy: 0.5980 - val_sparse_categorical_crossentropy: 0.9545\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 82s 1s/step - loss: 1.0611 - accuracy: 0.6683 - sparse_categorical_crossentropy: 0.8100 - val_loss: 1.0967 - val_accuracy: 0.6760 - val_sparse_categorical_crossentropy: 0.8566\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 1.0381 - accuracy: 0.6731 - sparse_categorical_crossentropy: 0.8039 - val_loss: 1.1539 - val_accuracy: 0.6240 - val_sparse_categorical_crossentropy: 0.9274\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 81s 1s/step - loss: 0.9652 - accuracy: 0.6988 - sparse_categorical_crossentropy: 0.7454 - val_loss: 1.0133 - val_accuracy: 0.6640 - val_sparse_categorical_crossentropy: 0.8022\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 72s 1s/step - loss: 0.9202 - accuracy: 0.7123 - sparse_categorical_crossentropy: 0.7127 - val_loss: 1.0081 - val_accuracy: 0.6960 - val_sparse_categorical_crossentropy: 0.8006\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.9727 - accuracy: 0.6828 - sparse_categorical_crossentropy: 0.7569 - val_loss: 1.0896 - val_accuracy: 0.6400 - val_sparse_categorical_crossentropy: 0.8685\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 77s 1s/step - loss: 0.9467 - accuracy: 0.6951 - sparse_categorical_crossentropy: 0.7427 - val_loss: 1.0264 - val_accuracy: 0.6600 - val_sparse_categorical_crossentropy: 0.8321\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 1.0081 - accuracy: 0.6960 - sparse_categorical_crossentropy: 0.8006\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-6\\assets\n",
      "--- Starting Trial: run-7\n",
      "{'lambda': 0.01}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 4.2065 - accuracy: 0.4231 - sparse_categorical_crossentropy: 1.5412 - val_loss: 2.1573 - val_accuracy: 0.5140 - val_sparse_categorical_crossentropy: 1.0982\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.7510 - accuracy: 0.5849 - sparse_categorical_crossentropy: 1.0030 - val_loss: 1.5289 - val_accuracy: 0.5940 - val_sparse_categorical_crossentropy: 0.9729\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 1.3612 - accuracy: 0.6446 - sparse_categorical_crossentropy: 0.8969 - val_loss: 1.3421 - val_accuracy: 0.6140 - val_sparse_categorical_crossentropy: 0.9429\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 81s 1s/step - loss: 1.2322 - accuracy: 0.6489 - sparse_categorical_crossentropy: 0.8564 - val_loss: 1.2131 - val_accuracy: 0.6100 - val_sparse_categorical_crossentropy: 0.8720\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.1626 - accuracy: 0.6613 - sparse_categorical_crossentropy: 0.8328 - val_loss: 1.2187 - val_accuracy: 0.6180 - val_sparse_categorical_crossentropy: 0.8867\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 1.1040 - accuracy: 0.6733 - sparse_categorical_crossentropy: 0.8004 - val_loss: 1.2788 - val_accuracy: 0.5540 - val_sparse_categorical_crossentropy: 0.9872\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.2131 - accuracy: 0.6100 - sparse_categorical_crossentropy: 0.8720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-7\\assets\n",
      "--- Starting Trial: run-8\n",
      "{'lambda': 0.05}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 80s 1s/step - loss: 9.2669 - accuracy: 0.3961 - sparse_categorical_crossentropy: 1.6217 - val_loss: 2.5937 - val_accuracy: 0.5020 - val_sparse_categorical_crossentropy: 1.2005\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 2.1867 - accuracy: 0.5215 - sparse_categorical_crossentropy: 1.1071 - val_loss: 2.0632 - val_accuracy: 0.4760 - val_sparse_categorical_crossentropy: 1.2073\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.8377 - accuracy: 0.5537 - sparse_categorical_crossentropy: 1.0531 - val_loss: 1.8842 - val_accuracy: 0.4280 - val_sparse_categorical_crossentropy: 1.2258\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.5937 - accuracy: 0.5020 - sparse_categorical_crossentropy: 1.2005\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-8\\assets\n",
      "--- Starting Trial: run-9\n",
      "{'lambda': 0.1}\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 13.6610 - accuracy: 0.3661 - sparse_categorical_crossentropy: 1.4795 - val_loss: 2.8100 - val_accuracy: 0.3840 - val_sparse_categorical_crossentropy: 1.2673\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 2.1864 - accuracy: 0.5225 - sparse_categorical_crossentropy: 1.1116 - val_loss: 1.8672 - val_accuracy: 0.5860 - val_sparse_categorical_crossentropy: 1.0934\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 78s 1s/step - loss: 1.6723 - accuracy: 0.5477 - sparse_categorical_crossentropy: 1.0680 - val_loss: 1.5274 - val_accuracy: 0.5660 - val_sparse_categorical_crossentropy: 1.0551\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.4658 - accuracy: 0.5547 - sparse_categorical_crossentropy: 1.0507 - val_loss: 1.4336 - val_accuracy: 0.5120 - val_sparse_categorical_crossentropy: 1.0736\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 79s 1s/step - loss: 1.2977 - accuracy: 0.5727 - sparse_categorical_crossentropy: 1.0022 - val_loss: 1.3221 - val_accuracy: 0.5480 - val_sparse_categorical_crossentropy: 1.0686\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 1.5274 - accuracy: 0.5660 - sparse_categorical_crossentropy: 1.0551\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 4 (Trousers&Jeans_All_L2)\\Run-9\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "for lambda_size in HP_LAMBDA.domain.values:\n",
    "    hparams = {\n",
    "        HP_LAMBDA : lambda_size\n",
    "    }\n",
    "    run_name = f'run-{session_num}'\n",
    "    print('--- Starting Trial:',run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run(\"Logs/Model 4 (Trousers&Jeans_All_L2)/hparam_tuning/\" + run_name, hparams, session_num)\n",
    "\n",
    "    session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TF2)",
   "language": "python",
   "name": "python3-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
